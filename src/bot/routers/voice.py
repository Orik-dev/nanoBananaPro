from __future__ import annotations

import os
import tempfile
import logging
import time
from aiogram import Router, F
from aiogram.types import Message
from aiogram.fsm.context import FSMContext

from speech_recognition import Recognizer, AudioFile, UnknownValueError, RequestError
from pydub import AudioSegment
from pydub.effects import normalize

from core.config import settings
from bot.states import GenStates, CreateStates
from services.queue import enqueue_generation

router = Router()
logger = logging.getLogger("voice")

# –ø—É—Ç—å –∫ ffmpeg –¥–ª—è pydub
AudioSegment.converter = settings.FFMPEG_PATH


@router.message(F.voice)
async def handle_voice_message(message: Message, state: FSMContext):
    """
    –ì–æ–ª–æ—Å–æ–≤–æ–π –ø—Ä–æ–º—Ç –¥–ª—è –≤—Å–µ—Ö –Ω—É–∂–Ω—ã—Ö —Å–æ—Å—Ç–æ—è–Ω–∏–π:
    - GenStates.waiting_prompt: —Ä–µ–¥–∞–∫—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –∑–∞–≥—Ä—É–∂–µ–Ω–Ω—ã—Ö —Ñ–æ—Ç–æ
    - GenStates.final_menu: –¥–æ–±–∞–≤–ª–µ–Ω–∏–µ –ø—Ä–∞–≤–∫–∏ –∫ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—É –∏ —Ä–µ–≥–µ–Ω–µ—Ä–∞—Ü–∏—è
    - CreateStates.waiting_prompt: –≥–µ–Ω–µ—Ä–∞—Ü–∏—è –±–µ–∑ —Ñ–æ—Ç–æ
    - CreateStates.selecting_aspect_ratio: –≥–æ–ª–æ—Å —Å—Ä–∞–∑—É ‚Üí AR=auto –∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏—è
    """
    user_id = message.from_user.id
    ogg_path = None
    wav_path = None
    
    caption = (message.caption or "").strip()
    if caption.startswith("/"):
        return

    cur = await state.get_state()
    data = await state.get_data()
    logger.info(f"[VOICE] user={user_id} state={cur}")

    # –ë–ª–æ–∫–∏—Ä—É–µ–º –≥–æ–ª–æ—Å —Ç–∞–º, –≥–¥–µ —ç—Ç–æ —Ç–æ—á–Ω–æ –Ω–µ –Ω—É–∂–Ω–æ
    if cur == GenStates.uploading_images.state:
        await message.answer(
            "‚ö†Ô∏è –°–Ω–∞—á–∞–ª–∞ –∑–∞–≥—Ä—É–∑–∏—Ç–µ 1‚Äì4 —Ñ–æ—Ç–æ–≥—Ä–∞—Ñ–∏–∏, –∫–æ—Ç–æ—Ä—ã–µ –Ω—É–∂–Ω–æ –∏–∑–º–µ–Ω–∏—Ç—å.\n"
            "–ü–æ—Å–ª–µ –∑–∞–≥—Ä—É–∑–∫–∏ –æ—Ç–ø—Ä–∞–≤—å—Ç–µ –≥–æ–ª–æ—Å–æ–≤–æ–µ —Å –æ–ø–∏—Å–∞–Ω–∏–µ–º –∏–∑–º–µ–Ω–µ–Ω–∏–π."
        )
        return
    if cur in (GenStates.generating.state, CreateStates.generating.state):
        await message.answer("‚è≥ –ü–æ–¥–æ–∂–¥–∏—Ç–µ, –∏–¥—ë—Ç –≥–µ–Ω–µ—Ä–∞—Ü–∏—è. –ü–æ—Ç–æ–º –º–æ–∂–Ω–æ –æ—Ç–ø—Ä–∞–≤–∏—Ç—å –Ω–æ–≤—ã–π –∑–∞–ø—Ä–æ—Å.")
        return

    # –°–æ–æ–±—â–µ–Ω–∏–µ ¬´—Ä–∞—Å–ø–æ–∑–Ω–∞—é‚Ä¶¬ª ‚Äî –¥–∞–ª—å—à–µ –µ–≥–æ –æ—Ç—Ä–µ–¥–∞–∫—Ç–∏—Ä—É–µ–º/—É–¥–∞–ª–∏–º
    processing_msg = await message.answer("üéôÔ∏è –†–∞—Å–ø–æ–∑–Ω–∞—é –≥–æ–ª–æ—Å...")

    try:
        # --- –∑–∞–≥—Ä—É–∑–∫–∞ –∏ –ø–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –∞—É–¥–∏–æ ---
        file = await message.bot.get_file(message.voice.file_id)
        voice_data = await message.bot.download_file(file.file_path)
        with tempfile.NamedTemporaryFile(suffix=".ogg", delete=False) as ogg_file:
            ogg_file.write(voice_data.getvalue())
            ogg_path = ogg_file.name

        audio = AudioSegment.from_file(ogg_path, format="ogg")
        audio = normalize(audio).set_channels(1).set_frame_rate(16000)
        wav_path = ogg_path.replace(".ogg", ".wav")
        audio.export(wav_path, format="wav", parameters=["-ar", "16000", "-ac", "1"])

        # --- —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ ---
        r = Recognizer()
        r.energy_threshold = 300
        r.dynamic_energy_threshold = True
        r.pause_threshold = 0.5
        r.non_speaking_duration = 0.3

        with AudioFile(wav_path) as src:
            r.adjust_for_ambient_noise(src, duration=0.3)
            audio_data = r.record(src)

        text = r.recognize_google(audio_data, language="ru-RU", show_all=False).strip()
        if not text or len(text) < 2:
            await processing_msg.edit_text(
                "‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å —Ä–∞—Å–ø–æ–∑–Ω–∞—Ç—å –≥–æ–ª–æ—Å.\n\n"
                "üí° –ì–æ–≤–æ—Ä–∏—Ç–µ —á—ë—Ç—á–µ, –∑–∞–ø–∏—à–∏—Ç–µ 2‚Äì3 —Å–µ–∫—É–Ω–¥—ã –∏ –∏–∑–±–µ–≥–∞–π—Ç–µ —à—É–º–∞."
            )
            return

        # –ø–æ–∫–∞–∑–∞—Ç—å —Ä–∞—Å–ø–æ–∑–Ω–∞–Ω–Ω—ã–π –ø—Ä–æ–º—Ç
        try:
            await processing_msg.edit_text(f"üéôÔ∏è <b>–†–∞—Å–ø–æ–∑–Ω–∞–Ω–æ:</b>\n\n<i>{text}</i>", parse_mode="HTML")
        except Exception:
            await message.answer(f"üéôÔ∏è <b>–†–∞—Å–ø–æ–∑–Ω–∞–Ω–æ:</b>\n\n<i>{text}</i>", parse_mode="HTML")
            try:
                await processing_msg.delete()
            except Exception:
                pass

        # ---------- –í–ï–¢–í–ò –ü–û –°–û–°–¢–û–Ø–ù–ò–Æ ----------

        # /gen: –∂–¥—ë–º –ø—Ä–æ–º—Ç –¥–ª—è —É–∂–µ –∑–∞–≥—Ä—É–∂–µ–Ω–Ω—ã—Ö —Ñ–æ—Ç–æ
        if cur == GenStates.waiting_prompt.state:
            photos = data.get("photos") or []
            if not photos:
                await message.answer("‚ùå –ù–µ—Ç –∑–∞–≥—Ä—É–∂–µ–Ω–Ω—ã—Ö —Ñ–æ—Ç–æ. –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ /gen –∏ –æ—Ç–ø—Ä–∞–≤—å—Ç–µ —Ñ–æ—Ç–æ —Å–Ω–∞—á–∞–ª–∞.")
                return
            file_ids = [p["file_id"] for p in photos]

            wait_msg = await message.answer("‚è≥ –ì–µ–Ω–µ—Ä–∏—Ä—É—é...")
            await state.set_state(GenStates.generating)
            await state.update_data(
                prompt=text,
                base_prompt=text,
                edits=[],
                mode="edit",
                wait_msg_id=wait_msg.message_id,
                gen_started_at=int(time.time()),
            )
            await enqueue_generation(user_id, text, file_ids)
            return

        # ‚úÖ –ù–û–í–û–ï: –≥–æ–ª–æ—Å–æ–≤—ã–µ –ø—Ä–∞–≤–∫–∏ –ø–æ—Å–ª–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞ /gen
        if cur == GenStates.final_menu.state:
            photos = data.get("photos") or []
            if not photos:
                await message.answer("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –Ω–∞–π—Ç–∏ –∏—Å—Ö–æ–¥–Ω—ã–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è. –ù–∞–∂–º–∏—Ç–µ ¬´–ù–∞—á–∞—Ç—å –∑–∞–Ω–æ–≤–æ¬ª.")
                return

            base_prompt = (data.get("base_prompt") or data.get("prompt") or "").strip()
            edits = list(data.get("edits") or [])
            edits.append(text)
            cumulative_prompt = " ".join([base_prompt] + edits).strip()
            if len(cumulative_prompt) > 4000:
                cumulative_prompt = cumulative_prompt[:4000]

            file_ids = [p["file_id"] for p in photos]
            wait_msg = await message.answer("‚è≥ –ì–µ–Ω–µ—Ä–∏—Ä—É—é...")

            await state.set_state(GenStates.generating)
            await state.update_data(
                prompt=cumulative_prompt,
                base_prompt=base_prompt,
                edits=edits,
                mode="edit",
                wait_msg_id=wait_msg.message_id,
                gen_started_at=int(time.time()),
            )
            await enqueue_generation(user_id, cumulative_prompt, file_ids)
            return

        # /create: –æ–±—ã—á–Ω–æ–µ –æ–∂–∏–¥–∞–Ω–∏–µ –ø—Ä–æ–º—Ç–∞
        if cur == CreateStates.waiting_prompt.state:
            aspect_ratio = data.get("aspect_ratio") or None
            wait_msg = await message.answer("‚è≥ –ì–µ–Ω–µ—Ä–∏—Ä—É—é...")
            await state.set_state(CreateStates.generating)
            await state.update_data(
                mode="create",
                prompt=text,
                wait_msg_id=wait_msg.message_id,
                gen_started_at=int(time.time()),
            )
            await enqueue_generation(user_id, text, [], aspect_ratio=aspect_ratio)
            return

        # /create: –≥–æ–ª–æ—Å –ø—Ä–∏—à—ë–ª, –ø–æ–∫–∞ –∂–¥—ë–º –≤—ã–±–æ—Ä AR ‚Äî –±–µ—Ä—ë–º –∞–≤—Ç–æ
        if cur == CreateStates.selecting_aspect_ratio.state:
            aspect_ratio = data.get("aspect_ratio") or None
            wait_msg = await message.answer("‚è≥ –ì–µ–Ω–µ—Ä–∏—Ä—É—é...")
            await state.set_state(CreateStates.generating)
            await state.update_data(
                mode="create",
                prompt=text,
                wait_msg_id=wait_msg.message_id,
                gen_started_at=int(time.time()),
                aspect_ratio=aspect_ratio,
            )
            await enqueue_generation(user_id, text, [], aspect_ratio=aspect_ratio)
            return

        # –ù–µ—Ç –∞–∫—Ç–∏–≤–Ω–æ–π —Å–µ—Å—Å–∏–∏
        await message.answer(
            "‚ÑπÔ∏è –î–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ:\n"
            "‚Ä¢ <b>/gen</b> ‚Äî —Ä–µ–¥–∞–∫—Ç–∏—Ä–æ–≤–∞—Ç—å —Ñ–æ—Ç–æ (–∑–∞–≥—Ä—É–∑–∏—Ç–µ —Ñ–æ—Ç–æ, –∑–∞—Ç–µ–º —Å–∫–∞–∂–∏—Ç–µ –ø—Ä–æ–º—Ç)\n"
            "‚Ä¢ <b>/create</b> ‚Äî —Å–æ–∑–¥–∞—Ç—å –Ω–æ–≤–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ (—Å–∫–∞–∂–∏—Ç–µ –ø—Ä–æ–º—Ç —Å—Ä–∞–∑—É)",
            parse_mode="HTML",
        )

    except UnknownValueError:
        try:
            await processing_msg.edit_text(
                "‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å —Ä–∞—Å–ø–æ–∑–Ω–∞—Ç—å —Ä–µ—á—å. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –≥–æ–≤–æ—Ä–∏—Ç—å –æ—Ç—á—ë—Ç–ª–∏–≤–µ–µ –∏ –∏–∑–±–µ–≥–∞—Ç—å —à—É–º–∞."
            )
        except Exception:
            await message.answer("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å —Ä–∞—Å–ø–æ–∑–Ω–∞—Ç—å —Ä–µ—á—å. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –µ—â—ë —Ä–∞–∑.")
    except RequestError as e:
        logger.error(f"[VOICE] Google API error: {e}")
        try:
            await processing_msg.edit_text("‚ùå –û—à–∏–±–∫–∞ —Å–µ—Ä–≤–∏—Å–∞ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è Google. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –ø–æ–∑–∂–µ.")
        except Exception:
            await message.answer("‚ùå –û—à–∏–±–∫–∞ —Å–µ—Ä–≤–∏—Å–∞ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è Google. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –ø–æ–∑–∂–µ.")
    except Exception:
        logger.exception("[VOICE] Unexpected error")
        try:
            await processing_msg.edit_text("‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –≥–æ–ª–æ—Å–æ–≤–æ–≥–æ. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –µ—â—ë —Ä–∞–∑.")
        except Exception:
            await message.answer("‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –≥–æ–ª–æ—Å–æ–≤–æ–≥–æ. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –µ—â—ë —Ä–∞–∑.")
    finally:
        # —á–∏—Å—Ç–∏–º –≤—Ä–µ–º–µ–Ω–Ω—ã–µ —Ñ–∞–π–ª—ã
        for p in (ogg_path, wav_path):
            if p and os.path.exists(p):
                try:
                    os.remove(p)
                except Exception:
                    pass
